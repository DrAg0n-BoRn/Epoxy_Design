{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_tools.ML_datasetmaster import DragonDataset\n",
    "from ml_tools.ML_models import DragonGateModel\n",
    "from ml_tools.ML_configuration import (\n",
    "    FormatRegressionMetrics,\n",
    "    FinalizeRegression, \n",
    "    DragonGateParams,\n",
    "    DragonTrainingConfig\n",
    ")\n",
    "\n",
    "from ml_tools.ML_trainer import DragonTrainer\n",
    "from ml_tools.ML_callbacks import DragonModelCheckpoint, DragonPatienceEarlyStopping, DragonPlateauScheduler\n",
    "from ml_tools.ML_utilities import build_optimizer_params\n",
    "from ml_tools.ML_utilities import inspect_model_architecture\n",
    "from ml_tools.utilities import load_dataframe_with_schema\n",
    "from ml_tools.IO_tools import train_logger\n",
    "from ml_tools.schema import FeatureSchema\n",
    "from ml_tools.keys import TaskKeys\n",
    "\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from paths import PM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = DragonTrainingConfig(\n",
    "    validation_size=0.2,\n",
    "    test_size=0.1,\n",
    "    initial_learning_rate=0.001,\n",
    "    batch_size=64,\n",
    "    task = TaskKeys.REGRESSION,\n",
    "    device = \"cuda\",\n",
    "    finalized_filename = \"gate_step2.pth\",\n",
    "    random_state=101,\n",
    "    \n",
    "    early_stop_patience=20,\n",
    "    scheduler_patience=3,\n",
    "    scheduler_lr_factor=0.5,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. Load Schema and Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = FeatureSchema.from_json(PM.engineering_artifacts_2)\n",
    "\n",
    "df, _ = load_dataframe_with_schema(df_path=PM.step2_data_file, schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3. Make Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DragonDataset(pandas_df=df,\n",
    "                        schema=schema,\n",
    "                        kind=train_config.task,\n",
    "                        feature_scaler=\"fit\",\n",
    "                        target_scaler=\"fit\",\n",
    "                        validation_size=train_config.validation_size,\n",
    "                        test_size=train_config.test_size,\n",
    "                        random_state=train_config.random_state,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 4. Model and Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = DragonGateParams(\n",
    "    schema=schema,\n",
    "    out_targets=dataset.number_of_targets,\n",
    "    embedding_dim=16,\n",
    "    gflu_stages = 6,\n",
    "    gflu_dropout = 0.1,\n",
    "    num_trees= 20,\n",
    "    tree_depth= 4,\n",
    "    tree_dropout= 0.1,\n",
    "    chain_trees= False,\n",
    "    tree_wise_attention= True,\n",
    "    tree_wise_attention_dropout= 0.1,\n",
    "    binning_activation= \"entmoid\",\n",
    "    feature_mask_function= \"entmax\",\n",
    "    share_head_weights= True,\n",
    "    batch_norm_continuous= True\n",
    ")\n",
    "\n",
    "model = DragonGateModel(**model_params)\n",
    "\n",
    "# Initialize decision thresholds before training.\n",
    "model.data_aware_initialization(train_dataset=dataset.train_dataset, num_samples=1000)\n",
    "\n",
    "# optimizer\n",
    "optim_params = build_optimizer_params(model=model, weight_decay=train_config.weight_decay)\n",
    "optimizer = AdamW(params=optim_params, lr=train_config.initial_learning_rate)\n",
    "\n",
    "trainer = DragonTrainer(model=model,\n",
    "                        train_dataset=dataset.train_dataset,\n",
    "                        validation_dataset=dataset.validation_dataset,\n",
    "                        kind=train_config.task,\n",
    "                        optimizer=optimizer,\n",
    "                        device=train_config.device,\n",
    "                        checkpoint_callback=DragonModelCheckpoint(save_dir=PM.train_checkpoints_2, \n",
    "                                                                  monitor=\"Validation Loss\"),\n",
    "                        early_stopping_callback=DragonPatienceEarlyStopping(patience=train_config.early_stop_patience, \n",
    "                                                                            monitor=\"Validation Loss\"),\n",
    "                        lr_scheduler_callback=DragonPlateauScheduler(monitor=\"Validation Loss\",\n",
    "                                                                     patience=train_config.scheduler_patience,\n",
    "                                                                     factor=train_config.scheduler_lr_factor),  \n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainer.fit(save_dir=PM.train_artifacts_2, epochs=500, batch_size=train_config.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(save_dir=PM.train_evaluation_2,\n",
    "                model_checkpoint=\"best\",\n",
    "                test_data=dataset.test_dataset,\n",
    "                val_format_configuration=FormatRegressionMetrics(scatter_color='mediumspringgreen'),\n",
    "                test_format_configuration=FormatRegressionMetrics(scatter_color='darkmagenta'),\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 7. Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.explain_captum(save_dir=PM.train_evaluation_2,\n",
    "                       n_samples=1000,\n",
    "                       n_steps=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## 8. Save artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset artifacts\n",
    "dataset.save_artifacts(PM.train_artifacts_2)\n",
    "\n",
    "# Model artifacts\n",
    "model.save_architecture(PM.train_artifacts_2)\n",
    "inspect_model_architecture(model=model, save_dir=PM.train_artifacts_2)\n",
    "\n",
    "# FeatureSchema\n",
    "schema.to_json(PM.train_artifacts_2)\n",
    "\n",
    "# Train log\n",
    "train_logger(train_config=train_config,\n",
    "             model_parameters=model_params,\n",
    "             train_history=history,\n",
    "             save_directory=PM.train_metrics_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 9. Finalize Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.finalize_model_training(model_checkpoint='current',\n",
    "                                save_dir=PM.train_artifacts_2,\n",
    "                                finalize_config=FinalizeRegression(filename=train_config.finalized_filename,\n",
    "                                                                    target_name=dataset.target_names[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epoxydesign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
